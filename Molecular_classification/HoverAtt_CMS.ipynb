{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision import models as torch_models1\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import pandas as pd\n",
    "from torch.utils.data import Sampler, BatchSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix, precision_recall_curve, f1_score\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.metrics import auc as calc_auc\n",
    "from topk.svm import SmoothTop1SVM\n",
    "from torch_kmeans import KMeans\n",
    "from topk.svm import SmoothTop1SVM\n",
    "from itertools import cycle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_excel('/home/ldap_howard/script/CRC_CMS.xlsx',sheet_name='CMS_0604')\n",
    "train_x = train_dataset['Patients'].values\n",
    "train_y = train_dataset['status']\n",
    "train_y = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_loader(path):\n",
    "    x = np.load(path,allow_pickle=True).item()\n",
    "    x_im = torch.from_numpy(x['features'])\n",
    "    return x_im\n",
    "\n",
    "def npy_loader_count(path):\n",
    "    x = np.load(path,allow_pickle=True).item()\n",
    "    x_im = torch.from_numpy(x['counts'])\n",
    "    #x_im = x_im[:,1:3]\n",
    "    return x_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.path = '/LVM_data/ldap_howard/feature/CRC_resnet0307/'\n",
    "        self.path_c = '/LVM_data/ldap_howard/feature/CRC_0307_MI2N/'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.path, self.x[idx]+'.npy')\n",
    "        count_path = os.path.join(self.path_c, self.x[idx]+'.npy')\n",
    "\n",
    "        return image_path, count_path, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight=None, \n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, logits, label):\n",
    "        log_prob = F.log_softmax(logits, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob, \n",
    "            label, \n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, L=2048, D=1024, dropout=True, n_classes=2, top_k=1):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = L\n",
    "        self.D = D\n",
    "        self.K = 1\n",
    "\n",
    "        self.layer1 = nn.Linear(self.L, self.D)\n",
    "        if dropout:\n",
    "            self.attention_V = nn.Sequential(nn.Linear(self.D, 512), nn.Tanh(), nn.Dropout(0.25))\n",
    "            self.attention_U = nn.Sequential(nn.Linear(self.D, 512), nn.Sigmoid(), nn.Dropout(0.25))\n",
    "        else:\n",
    "            self.attention_V = nn.Sequential(nn.Linear(self.D, 512), nn.Tanh())\n",
    "            self.attention_U = nn.Sequential(nn.Linear(self.D, 512), nn.Sigmoid())\n",
    "\n",
    "        self.attention_weights = nn.Linear(512, self.K)\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.Linear(1028,1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.25),\n",
    "                                        nn.Linear(1024, 512),\n",
    "                                        nn.ReLU(), \n",
    "                                        nn.Linear(512,4),\n",
    "                                        nn.Sigmoid())\n",
    "        self.top_k = top_k\n",
    "        self.instance_loss = nn.CrossEntropyLoss()\n",
    "        self.fc_c1 = nn.Sequential(nn.Linear(4, 4), nn.ReLU())\n",
    "        self.fc_X = nn.Sequential(nn.Linear(1, 4), nn.Sigmoid())\n",
    "\n",
    "    def relocate(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.classifier.to(device)\n",
    "        self.attention_V.to(device)\n",
    "        self.attention_U.to(device)\n",
    "        self.attention_weights.to(device)\n",
    "        self.instance_loss.to(device)\n",
    "        self.fc_c.to(device)\n",
    "        self.fc_X.to(device)\n",
    "    \n",
    "    def inst_eval(self, A_T, count):\n",
    "        logits_c = self.fc_c1(count)\n",
    "        hover_logits = torch.mm(A_T, logits_c)\n",
    "        y_probs_c = F.softmax(logits_c, dim=1)\n",
    "        #k = math.ceil(logits_c.size()[0] / 20)\n",
    "        _, predicted_class = torch.max(y_probs_c, dim=1)\n",
    "        predicted_prob = y_probs_c[torch.arange(y_probs_c.size(0)), predicted_class]\n",
    "        top_instance_idx = torch.topk(predicted_prob, 5, largest=True)[1]\n",
    "        top_instance = torch.index_select(y_probs_c, dim=0, index=top_instance_idx)\n",
    "        _, pseudo_targets = torch.max(top_instance, dim=1)\n",
    "\n",
    "        A_T = torch.transpose(A_T, 1, 0)  # KxN\n",
    "        logits_x = self.fc_X(A_T)\n",
    "        y_probs_x = F.softmax(logits_x, dim=1)\n",
    "        top_instance_x = torch.index_select(logits_x, dim=0, index=top_instance_idx)\n",
    "        pseudo_logits = top_instance_x\n",
    "\n",
    "        return pseudo_logits, pseudo_targets,  hover_logits\n",
    "\n",
    "    def forward(self, x, count, eval=False):\n",
    "        x = self.layer1(x)\n",
    "        A_V = self.attention_V(x)  # NxD\n",
    "        A_U = self.attention_U(x)\n",
    "        A = self.attention_weights(A_V*A_U)\n",
    "        A_T = torch.transpose(A, 1, 0)  # KxN\n",
    "        A_T = F.softmax(A_T, dim=1)  # softmax over N\n",
    "        M = torch.mm(A_T, x)  # KxL\n",
    "\n",
    "        pseudo_logits, pseudo_targets, hover_logits = self.inst_eval(A_T, count)\n",
    "        instance_loss = self.instance_loss(pseudo_logits, pseudo_targets)\n",
    "        M  = torch.cat((M, hover_logits), dim=1)\n",
    "       \n",
    "        logits = self.classifier(M)\n",
    "        y_probs = F.softmax(logits, dim=1)\n",
    "        max_scores, max_indice = torch.max(y_probs, dim=1)\n",
    "        Y_hat = max_indice\n",
    "        Y_prob = y_probs\n",
    "        results_dict = {}\n",
    "        if eval == False:\n",
    "            results_dict.update({'logits': logits, 'Y_prob': Y_prob, 'Y_hat': Y_hat, 'Instance_loss': instance_loss, 'hover_logits':hover_logits})\n",
    "        elif eval == True:\n",
    "            results_dict.update({'logits': logits, 'Y_prob': Y_prob, 'Y_hat': Y_hat,})\n",
    "\n",
    "\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy_Logger(object):\n",
    "    \"\"\"Accuracy logger\"\"\"\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(Accuracy_Logger, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        self.data = [{\"count\": 0, \"correct\": 0} for i in range(self.n_classes)]\n",
    "\n",
    "    def log(self, Y_hat, Y):\n",
    "        Y_hat = int(Y_hat)\n",
    "        Y = int(Y)\n",
    "        self.data[Y][\"count\"] += 1\n",
    "        self.data[Y][\"correct\"] += (Y_hat == Y)\n",
    "\n",
    "    def log_batch(self, count, correct, c):\n",
    "        self.data[c][\"count\"] += count\n",
    "        self.data[c][\"correct\"] += correct\n",
    "\n",
    "    def log_batch_rnn(self, Y_hat, Y):\n",
    "        Y_hat = np.array(Y_hat).astype(int)\n",
    "        Y = np.array(Y).astype(int)\n",
    "        for label_class in np.unique(Y):\n",
    "            cls_mask = Y == label_class\n",
    "            self.data[label_class][\"count\"] += cls_mask.sum()\n",
    "            self.data[label_class][\"correct\"] += (Y_hat[cls_mask] == Y[cls_mask]).sum()\n",
    "\n",
    "    def get_summary(self, c):\n",
    "        count = self.data[c][\"count\"]\n",
    "        correct = self.data[c][\"correct\"]\n",
    "\n",
    "        if count == 0:\n",
    "            acc = None\n",
    "        else:\n",
    "            acc = float(correct) / count\n",
    "\n",
    "        return acc, correct, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(Y_hat, Y):\n",
    "    error = 1. - Y_hat.float().eq(Y.float()).float().mean().item()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=40, stop_epoch=100, verbose=False):  # 连续patience轮，并且总论此超过stop_epoch轮就会终止\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 20\n",
    "            stop_epoch (int): Earliest epoch possible for stopping\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.stop_epoch = stop_epoch\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_max = np.Inf\n",
    "\n",
    "    def __call__(self, epoch, val_loss, model, ckpt_name='checkpoint.pt'):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, ckpt_name)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            logging.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience and epoch > self.stop_epoch:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, ckpt_name)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, early_stopping, model, ckpt_name):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            logging.info(\n",
    "                f'Validation loss decreased ({self.val_loss_max:.6f} --> {early_stopping:.6f}).  Saving model ...')\n",
    "        print(\"Save model!!!!!!!!!!!\")\n",
    "        torch.save(model.state_dict(), ckpt_name)\n",
    "        self.val_loss_max = early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_to_excel(fold, loader_name, label_list, probs_list, y_hat_list, accuracy, precision, recall, f1, cls_auc):\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Patients\": loader_name,\n",
    "            \"labels\": label_list,\n",
    "            \"CMS1_probs\": probs_list[:,0],\n",
    "            \"CMS2_probs\": probs_list[:,1],\n",
    "            \"CMS3_probs\": probs_list[:,2],\n",
    "            \"CMS4_probs\": probs_list[:,3], \n",
    "            \"y_hat\": y_hat_list,\n",
    "            \"Accuracy\" : accuracy,\n",
    "            \"Auc\": cls_auc\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if fold == 0:\n",
    "        with pd.ExcelWriter('./summary/0307/CMS/CMS_0307CV7_clam.xlsx', engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, sheet_name='Sheet0', index=False)\n",
    "    else:\n",
    "        with pd.ExcelWriter('./summary/0307/CMS/CMS_0307CV7_clam.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            df.to_excel(writer, sheet_name='Sheet'+str(fold), index=False)\n",
    "\n",
    "    print(\"Patients data is successfully written into Excel File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model, loader, n_classes, fold):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #cls_logger = Accuracy_Logger(n_classes=n_classes)\n",
    "    model.eval()\n",
    "    cls_test_error = 0.\n",
    "    cls_test_loss = 0.\n",
    "\n",
    "    all_cls_probs = np.zeros((len(loader), n_classes))\n",
    "    all_cls_logits = np.zeros((len(loader), n_classes))\n",
    "    all_cls_labels = np.zeros(len(loader))\n",
    "    all_cls_y_hats = np.zeros(len(loader))\n",
    "    all_cls_onehot = np.zeros((len(loader), n_classes))\n",
    "\n",
    "    patient_results = {}\n",
    "    \n",
    "    loader_name = []\n",
    "    for batch_idx, (npy_dir, npy_dir_count, label) in enumerate(loader):\n",
    "        data = npy_loader(npy_dir[0]).to(device)\n",
    "        count = npy_loader_count(npy_dir_count[0]).to(device)\n",
    "        label_numpy = label.cpu().numpy()\n",
    "        label = label.to(device)\n",
    "        label_onehot = label_binarize(label_numpy, classes=np.arange(4))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            results_dict = model(data, count, eval=True)\n",
    "\n",
    "        logits, Y_prob, Y_hat = results_dict['logits'], results_dict['Y_prob'], results_dict['Y_hat']\n",
    "        loader_name.append(npy_dir[0])\n",
    "\n",
    "        #cls_logger.log(Y_hat, label)\n",
    "        cls_logits = logits.cpu().numpy()\n",
    "        cls_probs = Y_prob.cpu().numpy()\n",
    "        cls_Yhats = Y_hat.cpu().numpy()\n",
    "        all_cls_logits[batch_idx] = cls_logits\n",
    "        all_cls_probs[batch_idx] = cls_probs\n",
    "        all_cls_labels[batch_idx] = label.item()\n",
    "        all_cls_y_hats[batch_idx] = cls_Yhats.item()\n",
    "        all_cls_onehot[batch_idx] = label_onehot\n",
    "\n",
    "        cls_error = calculate_error(Y_hat, label)\n",
    "        cls_test_error += cls_error\n",
    "\n",
    "    cls_test_error /= len(loader)\n",
    "\n",
    "    if n_classes == 2:\n",
    "        print(all_cls_labels)\n",
    "        print(all_cls_y_hats)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_cls_labels, all_cls_y_hats, labels=[0, 1]).ravel()\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        try:\n",
    "            cls_auc = roc_auc_score(all_cls_labels, all_cls_probs[:, 1])\n",
    "            precision1, recall1, _ = precision_recall_curve(all_cls_labels,all_cls_probs[:,1])\n",
    "            auprc = calc_auc(recall1, precision1)\n",
    "        except:\n",
    "            cls_auc = 'nan'\n",
    "            auprc = 'nan'\n",
    "        print(\"Accuracy: \"+str(accuracy))\n",
    "        print(\"Specificity: \"+str(specificity))\n",
    "        print(\"Sensitivity: \"+str(sensitivity))\n",
    "        print(\"Recall: \"+str(recall))\n",
    "        print(\"Precision: \"+str(precision))\n",
    "        print(\"Auc: \"+str(cls_auc))\n",
    "        print(\"AUPRC: \"+str(auprc))\n",
    "\n",
    "        summary_to_excel(fold, loader_name, all_cls_labels, all_cls_probs[:,1], all_cls_y_hats, \n",
    "                         accuracy, specificity, sensitivity, precision, f1_score, cls_auc, auprc)\n",
    "    else:\n",
    "        auc_scores = {}\n",
    "        for i in range(n_classes):\n",
    "            try:\n",
    "                # Binary labels: 1 for the current class, 0 for the rest\n",
    "                binary_labels = (all_cls_labels == i).astype(int)\n",
    "                cls_auc = roc_auc_score(binary_labels, all_cls_probs[:, i])\n",
    "                auc_scores[f'Class {i}'] = cls_auc\n",
    "            except ValueError as e:\n",
    "                auc_scores[f'Class {i}'] = 'nan'\n",
    "        \n",
    "        # Print AUROC scores for each class\n",
    "        for class_label, auc in auc_scores.items():\n",
    "            print(f\"{class_label} AUROC: {auc}\")\n",
    "            \n",
    "        cls_auc = roc_auc_score(all_cls_labels, all_cls_probs, multi_class='ovr')\n",
    "        correct = (all_cls_y_hats == all_cls_labels).sum().item()\n",
    "        accuracy = float(correct / all_cls_labels.shape[0])\n",
    "        precision = precision_score(all_cls_y_hats, all_cls_labels, average=None)\n",
    "        recall = recall_score(all_cls_y_hats, all_cls_labels, average=None)\n",
    "        f1 = f1_score(all_cls_y_hats, all_cls_labels, average=None)\n",
    "        print(\"Accuracy: \"+str(accuracy))\n",
    "        print(\"Precision: \"+str(precision))\n",
    "        print(\"Recall: \"+str(recall))\n",
    "        print(\"f1: \"+str(f1))\n",
    "        print(all_cls_onehot)\n",
    "        summary_to_excel(fold, loader_name, all_cls_labels, all_cls_probs, all_cls_y_hats, \n",
    "                         accuracy, precision, recall, f1, cls_auc)\n",
    "\n",
    "    return patient_results, cls_test_error, cls_auc, all_cls_onehot, all_cls_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(tprs, mean_fpr):\n",
    "    plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_auc = calc_auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "            label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('ROC', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(train_loss, valid_loss, fold):\n",
    "    title = 'CMS HoverAtt-CMS fold' + str(fold+1) + ' loss curve'\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='validation loss')\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.savefig('/home/ldap_howard/script/summary/attention_hover/loss_fold'+str(fold)+'_clam.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, model, loader, optimizer, n_classes, writer=None, loss_fn=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    cls_logger = Accuracy_Logger(n_classes=n_classes)\n",
    "    cls_train_error = 0.\n",
    "    cls_train_loss = 0.\n",
    "    train_inst_loss = 0.\n",
    "    total_loss = 0.\n",
    "    for batch_idx, (npy_dir, npy_dir_count, label) in enumerate(loader):\n",
    "        data = npy_loader(npy_dir[0]).to(device)\n",
    "        count = npy_loader_count(npy_dir_count[0]).to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        results_dict = model(data, count)\n",
    "        logits, Y_prob, Y_hat, instance_loss, hover_logits = results_dict['logits'], results_dict['Y_prob'], results_dict['Y_hat'], results_dict['Instance_loss'], results_dict['hover_logits']\n",
    "\n",
    "        cls_loss = loss_fn(logits, label)\n",
    "        cls_loss_value = cls_loss.item()\n",
    "\n",
    "        hover_loss = loss_fn(hover_logits, label)\n",
    "        hover_loss_value = hover_loss.item()\n",
    "\n",
    "        total_loss = 0.95*cls_loss + 0.05*instance_loss\n",
    "        cls_train_loss += cls_loss.item()\n",
    "\n",
    "        cls_error = calculate_error(Y_hat, label)\n",
    "        cls_train_error += cls_error\n",
    "\n",
    "        # backward pass\n",
    "        total_loss.backward()\n",
    "        # step\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # calculate loss and error for epoch\n",
    "    cls_train_loss /= len(loader)\n",
    "    cls_train_error /= len(loader)\n",
    "\n",
    "    return cls_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model_name, epoch, model, loader, n_classes, early_stopping=None, writer=None, loss_fn=None, results_dir=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    #cls_logger = Accuracy_Logger(n_classes=n_classes)\n",
    "    cls_val_error = 0.\n",
    "    cls_val_loss = 0.\n",
    "\n",
    "    cls_probs = np.zeros((len(loader), n_classes))\n",
    "    cls_labels = np.zeros(len(loader))\n",
    "    all_cls_labels = np.zeros(len(loader))\n",
    "    all_cls_y_hats = np.zeros(len(loader))\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (npy_dir, npy_dir_count, label) in enumerate(loader):\n",
    "            data = npy_loader(npy_dir[0]).to(device)\n",
    "            count = npy_loader_count(npy_dir_count[0]).to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            results_dict = model(data, count)\n",
    "            logits, Y_prob, Y_hat = results_dict['logits'], results_dict['Y_prob'], results_dict['Y_hat']\n",
    "            del results_dict\n",
    "\n",
    "            cls_loss = loss_fn(logits, label)\n",
    "            cls_loss_value = cls_loss.item()\n",
    "\n",
    "            cls_probs[batch_idx] = Y_prob.cpu().numpy()\n",
    "            cls_labels[batch_idx] = label.item()\n",
    "\n",
    "            cls_val_loss += cls_loss_value\n",
    "            cls_error = calculate_error(Y_hat, label)\n",
    "            cls_val_error += cls_error\n",
    "\n",
    "            cls_Yhats = Y_hat.cpu().numpy()\n",
    "            all_cls_labels[batch_idx] = label.item()\n",
    "            all_cls_y_hats[batch_idx] = cls_Yhats.item()            \n",
    "\n",
    "    cls_val_error /= len(loader)\n",
    "    cls_val_loss /= len(loader)\n",
    "\n",
    "    all_cls_labels[batch_idx] = label.item()\n",
    "    all_cls_y_hats[batch_idx] = cls_Yhats.item()\n",
    "\n",
    "    print(\"cls val loss: \" + str(cls_val_loss))\n",
    "\n",
    "    if n_classes == 2:\n",
    "        cls_auc = roc_auc_score(cls_labels, cls_probs[:, 1])\n",
    "        precision1, recall1, _ = precision_recall_curve(cls_labels,cls_probs[:, 1])\n",
    "        cls_auprc = calc_auc(recall1, precision1)     \n",
    "        cls_aucs = []\n",
    "    else:\n",
    "        cls_aucs = []\n",
    "        binary_labels = label_binarize(cls_labels, classes=[i for i in range(n_classes)])\n",
    "        correct = (all_cls_y_hats == all_cls_labels).sum().item()\n",
    "        accuracy = float(correct / all_cls_labels.shape[0])\n",
    "        for class_idx in range(n_classes):\n",
    "            if class_idx in cls_labels:\n",
    "                fpr, tpr, _ = roc_curve(binary_labels[:, class_idx], cls_probs[:, class_idx])\n",
    "                cls_aucs.append(calc_auc(fpr, tpr))\n",
    "            else:\n",
    "                cls_aucs.append(float('nan'))\n",
    "\n",
    "        cls_auc = np.nanmean(np.array(cls_aucs))\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    print(\"cls_auprc: \" + str(cls_auc))\n",
    "\n",
    "    if early_stopping:\n",
    "        assert results_dir\n",
    "        early_stopping(epoch, cls_val_loss, model,\n",
    "                       ckpt_name=os.path.join(results_dir, model_name))\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(\"Early stopping\")\n",
    "            return cls_val_loss, True\n",
    "\n",
    "    return cls_val_loss, False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossCustom(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='none'):\n",
    "        super(FocalLossCustom, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def forward(self, logits, label, pseudo_targets):\n",
    "        ce_loss = F.cross_entropy(logits,label, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        N = len(pseudo_targets)\n",
    "        pseudo_targets = torch.mean(pseudo_targets, dim=0).unsqueeze(0)\n",
    "        ce_loss_pseudo = F.cross_entropy(pseudo_targets, label, reduction='none')\n",
    "        pt_pseudo = torch.exp(-ce_loss_pseudo)\n",
    "        \n",
    "        focal_loss = 0.8*(self.alpha * (1 - pt) ** self.gamma * ce_loss) + 0.2*ce_loss_pseudo / math.log(N)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SimpleDataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "early_stopping = None\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "0\n",
      "cls val loss: 1.281624504498073\n",
      "Accuracy: 0.44047619047619047\n",
      "cls_auprc: 0.581200842710284\n",
      "Save model!!!!!!!!!!!\n",
      "1\n",
      "cls val loss: 1.262003351535116\n",
      "Accuracy: 0.44047619047619047\n",
      "cls_auprc: 0.5920004810591597\n",
      "Save model!!!!!!!!!!!\n",
      "2\n",
      "cls val loss: 1.2408851463170278\n",
      "Accuracy: 0.4642857142857143\n",
      "cls_auprc: 0.6558464158590915\n",
      "Save model!!!!!!!!!!!\n",
      "3\n",
      "cls val loss: 1.2326319104149228\n",
      "Accuracy: 0.47619047619047616\n",
      "cls_auprc: 0.6647492648748878\n",
      "Save model!!!!!!!!!!!\n",
      "4\n",
      "cls val loss: 1.2534320318982715\n",
      "Accuracy: 0.4642857142857143\n",
      "cls_auprc: 0.6432675683191648\n",
      "5\n",
      "cls val loss: 1.1971745888392131\n",
      "Accuracy: 0.5119047619047619\n",
      "cls_auprc: 0.6740196801806702\n",
      "Save model!!!!!!!!!!!\n",
      "6\n",
      "cls val loss: 1.1842963901304064\n",
      "Accuracy: 0.5119047619047619\n",
      "cls_auprc: 0.6883973353961459\n",
      "Save model!!!!!!!!!!!\n",
      "7\n",
      "cls val loss: 1.2012774738527479\n",
      "Accuracy: 0.5\n",
      "cls_auprc: 0.6890236300013318\n",
      "8\n",
      "cls val loss: 1.1753797445978438\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7177553787587186\n",
      "Save model!!!!!!!!!!!\n",
      "9\n",
      "cls val loss: 1.1659055792150044\n",
      "Accuracy: 0.5238095238095238\n",
      "cls_auprc: 0.7033409396251298\n",
      "Save model!!!!!!!!!!!\n",
      "10\n",
      "cls val loss: 1.1648206994647072\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.6997838308457364\n",
      "Save model!!!!!!!!!!!\n",
      "11\n",
      "cls val loss: 1.1584530167636418\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.7111970923385978\n",
      "Save model!!!!!!!!!!!\n",
      "12\n",
      "cls val loss: 1.1459915609586806\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7387682251763467\n",
      "Save model!!!!!!!!!!!\n",
      "13\n",
      "cls val loss: 1.1578977625994455\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.759864409319263\n",
      "14\n",
      "cls val loss: 1.1585715782074701\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7370261901301196\n",
      "15\n",
      "cls val loss: 1.1542659181924093\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7711329300715049\n",
      "16\n",
      "cls val loss: 1.130103200674057\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7431958940735779\n",
      "Save model!!!!!!!!!!!\n",
      "17\n",
      "cls val loss: 1.1438264910663878\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7334852688780154\n",
      "18\n",
      "cls val loss: 1.1457126956610453\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7482476624083407\n",
      "19\n",
      "cls val loss: 1.1492690358843123\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7095399247519567\n",
      "20\n",
      "cls val loss: 1.1330611223266238\n",
      "Accuracy: 0.6309523809523809\n",
      "cls_auprc: 0.7480082031745565\n",
      "21\n",
      "cls val loss: 1.1494955122470856\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7494908768987374\n",
      "22\n",
      "cls val loss: 1.1308887749910355\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7531553144361666\n",
      "23\n",
      "cls val loss: 1.14253364219552\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7549459331887018\n",
      "24\n",
      "cls val loss: 1.1367570126340503\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7529092306002523\n",
      "25\n",
      "cls val loss: 1.139454172480674\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7421772207189952\n",
      "26\n",
      "cls val loss: 1.1376349606684275\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7494922596379291\n",
      "27\n",
      "cls val loss: 1.1294683892102468\n",
      "Accuracy: 0.6190476190476191\n",
      "cls_auprc: 0.7668770195017784\n",
      "Save model!!!!!!!!!!!\n",
      "28\n",
      "cls val loss: 1.1239827913897378\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7710350484742202\n",
      "Save model!!!!!!!!!!!\n",
      "29\n",
      "cls val loss: 1.127967322866122\n",
      "Accuracy: 0.5238095238095238\n",
      "cls_auprc: 0.7656204301362873\n",
      "30\n",
      "cls val loss: 1.145983480981418\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7619896050812818\n",
      "31\n",
      "cls val loss: 1.137526430544399\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7633824901045676\n",
      "32\n",
      "cls val loss: 1.1604819418418975\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7235213112183173\n",
      "33\n",
      "cls val loss: 1.129368517370451\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7689708589280804\n",
      "34\n",
      "cls val loss: 1.159234602536474\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.7392919558173867\n",
      "35\n",
      "cls val loss: 1.1476615709917886\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7536724027155117\n",
      "36\n",
      "cls val loss: 1.1384875419593992\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7578241733016491\n",
      "37\n",
      "cls val loss: 1.136233478074982\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7582322575161601\n",
      "38\n",
      "cls val loss: 1.1274746528693609\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7701446245209145\n",
      "39\n",
      "cls val loss: 1.1295468736262548\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7818969594512717\n",
      "40\n",
      "cls val loss: 1.1389785075471515\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7748542127054645\n",
      "41\n",
      "cls val loss: 1.168529925601823\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7451736485230085\n",
      "42\n",
      "cls val loss: 1.1371213077079683\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7721326378109863\n",
      "43\n",
      "cls val loss: 1.1903498293388457\n",
      "Accuracy: 0.5238095238095238\n",
      "cls_auprc: 0.7464892020790059\n",
      "44\n",
      "cls val loss: 1.1285516910609745\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.758779145849563\n",
      "45\n",
      "cls val loss: 1.1202112549827212\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7767877219050737\n",
      "Save model!!!!!!!!!!!\n",
      "46\n",
      "cls val loss: 1.151540668237777\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7746996311855461\n",
      "47\n",
      "cls val loss: 1.1408034641118276\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7681239743540518\n",
      "48\n",
      "cls val loss: 1.1714353667838233\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7274466323797593\n",
      "49\n",
      "cls val loss: 1.1547585399377913\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.7445220565430976\n",
      "50\n",
      "cls val loss: 1.1299867530663807\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7668645131716498\n",
      "51\n",
      "cls val loss: 1.133770316129639\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7545510467003478\n",
      "52\n",
      "cls val loss: 1.1468878892206011\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.761147144170954\n",
      "53\n",
      "cls val loss: 1.1144672568355287\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.797286977038293\n",
      "Save model!!!!!!!!!!!\n",
      "54\n",
      "cls val loss: 1.1348296347118558\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7545996509220884\n",
      "55\n",
      "cls val loss: 1.1422437663589204\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7559814261644366\n",
      "56\n",
      "cls val loss: 1.1031453169527508\n",
      "Accuracy: 0.6190476190476191\n",
      "cls_auprc: 0.7871993338529796\n",
      "Save model!!!!!!!!!!!\n",
      "57\n",
      "cls val loss: 1.115675966654505\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7752396737511851\n",
      "58\n",
      "cls val loss: 1.1454388087704068\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7538540268233673\n",
      "59\n",
      "cls val loss: 1.1248642859004794\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7630811167337572\n",
      "60\n",
      "cls val loss: 1.1170667218310493\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7679591821310376\n",
      "61\n",
      "cls val loss: 1.1356053430409658\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7610918064477616\n",
      "62\n",
      "cls val loss: 1.1101588848091306\n",
      "Accuracy: 0.6190476190476191\n",
      "cls_auprc: 0.7739349767535093\n",
      "63\n",
      "cls val loss: 1.1300514397167025\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7533767306408279\n",
      "64\n",
      "cls val loss: 1.125096885221345\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7647850358982025\n",
      "65\n",
      "cls val loss: 1.1344882242736363\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.765465407130946\n",
      "66\n",
      "cls val loss: 1.1342268011399679\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7532837388749414\n",
      "67\n",
      "cls val loss: 1.121241216148649\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7661305450738839\n",
      "68\n",
      "cls val loss: 1.1346879267976397\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7795019090050453\n",
      "69\n",
      "cls val loss: 1.148909907965433\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7652028372987837\n",
      "70\n",
      "cls val loss: 1.1317235848733358\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7712469145999873\n",
      "71\n",
      "cls val loss: 1.1285839087906337\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7859208509632912\n",
      "72\n",
      "cls val loss: 1.1211039267835163\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.767955626290163\n",
      "73\n",
      "cls val loss: 1.1410400044350397\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7763126172017772\n",
      "74\n",
      "cls val loss: 1.1467123279968898\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7709955471550026\n",
      "75\n",
      "cls val loss: 1.1185638599452519\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7644341827338312\n",
      "76\n",
      "cls val loss: 1.1328572623786473\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7439717026267838\n",
      "77\n",
      "cls val loss: 1.125625608222825\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7615492162525457\n",
      "78\n",
      "cls val loss: 1.1507422150600524\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.7412792630196379\n",
      "79\n",
      "cls val loss: 1.1590807941697894\n",
      "Accuracy: 0.5238095238095238\n",
      "cls_auprc: 0.7225601193874953\n",
      "80\n",
      "cls val loss: 1.1182131185418083\n",
      "Accuracy: 0.5595238095238095\n",
      "cls_auprc: 0.7881164001236357\n",
      "81\n",
      "cls val loss: 1.1314201262735186\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7845467484736264\n",
      "82\n",
      "cls val loss: 1.124366521125748\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7472273187422007\n",
      "83\n",
      "cls val loss: 1.1282206255765188\n",
      "Accuracy: 0.6190476190476191\n",
      "cls_auprc: 0.7623425458430189\n",
      "84\n",
      "cls val loss: 1.1112631332306635\n",
      "Accuracy: 0.6190476190476191\n",
      "cls_auprc: 0.7622646036743352\n",
      "85\n",
      "cls val loss: 1.1601721317995162\n",
      "Accuracy: 0.5357142857142857\n",
      "cls_auprc: 0.7477699132807697\n",
      "86\n",
      "cls val loss: 1.1542749993857884\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7801818846700979\n",
      "87\n",
      "cls val loss: 1.1190676987171173\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7695422044064193\n",
      "88\n",
      "cls val loss: 1.1103393563202448\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7650533388661972\n",
      "89\n",
      "cls val loss: 1.1236203057425362\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7624839580582164\n",
      "90\n",
      "cls val loss: 1.175593071040653\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7434553298896875\n",
      "91\n",
      "cls val loss: 1.169665691398439\n",
      "Accuracy: 0.47619047619047616\n",
      "cls_auprc: 0.7418459433879317\n",
      "92\n",
      "cls val loss: 1.1245899704240618\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7583917349570293\n",
      "93\n",
      "cls val loss: 1.1232305722577232\n",
      "Accuracy: 0.6309523809523809\n",
      "cls_auprc: 0.7631975725162183\n",
      "94\n",
      "cls val loss: 1.123601565048808\n",
      "Accuracy: 0.5952380952380952\n",
      "cls_auprc: 0.7738463479646163\n",
      "95\n",
      "cls val loss: 1.133632901169005\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7627361240376087\n",
      "96\n",
      "cls val loss: 1.144547851312728\n",
      "Accuracy: 0.5714285714285714\n",
      "cls_auprc: 0.7597488886476241\n",
      "97\n",
      "cls val loss: 1.1120151749679021\n",
      "Accuracy: 0.6071428571428571\n",
      "cls_auprc: 0.7640672479265853\n",
      "98\n",
      "cls val loss: 1.1168554155599504\n",
      "Accuracy: 0.5476190476190477\n",
      "cls_auprc: 0.7735135581032061\n",
      "99\n",
      "cls val loss: 1.1152755639382772\n",
      "Accuracy: 0.6428571428571429\n",
      "cls_auprc: 0.7520656607950402\n",
      "100\n",
      "cls val loss: 1.1441413440874644\n",
      "Accuracy: 0.5238095238095238\n",
      "cls_auprc: 0.7579060608157785\n",
      "101\n",
      "cls val loss: 1.1259397239912123\n",
      "Accuracy: 0.5833333333333334\n",
      "cls_auprc: 0.7713082120787577\n",
      "EarlyStopping\n",
      "Class 0 AUROC: 0.9219934994582881\n",
      "Class 1 AUROC: 0.8142610695802186\n",
      "Class 2 AUROC: 0.6354166666666666\n",
      "Class 3 AUROC: 0.777126099706745\n",
      "Accuracy: 0.6190476190476191\n",
      "Precision: [0.46153846 0.78378378 0.33333333 0.59090909]\n",
      "Recall: [0.85714286 0.70731707 0.36363636 0.52      ]\n",
      "f1: [0.6        0.74358974 0.34782609 0.55319149]\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "Patients data is successfully written into Excel File\n",
      "Validation acc: 0.7871993338529796\n",
      "validation error: 0.38095238095238093\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "0\n",
      "cls val loss: 1.2736002012907741\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.6717199370340137\n",
      "Save model!!!!!!!!!!!\n",
      "1\n",
      "cls val loss: 1.2684679469430302\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6494571132958662\n",
      "Save model!!!!!!!!!!!\n",
      "2\n",
      "cls val loss: 1.266814985189093\n",
      "Accuracy: 0.40963855421686746\n",
      "cls_auprc: 0.627075990377056\n",
      "Save model!!!!!!!!!!!\n",
      "3\n",
      "cls val loss: 1.2619266057588967\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.6592452321446534\n",
      "Save model!!!!!!!!!!!\n",
      "4\n",
      "cls val loss: 1.2398430073117634\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6633507410462391\n",
      "Save model!!!!!!!!!!!\n",
      "5\n",
      "cls val loss: 1.2376547534781766\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7045672863863223\n",
      "Save model!!!!!!!!!!!\n",
      "6\n",
      "cls val loss: 1.2195529442235649\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6918732949380384\n",
      "Save model!!!!!!!!!!!\n",
      "7\n",
      "cls val loss: 1.2331978326820465\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7083405542543524\n",
      "8\n",
      "cls val loss: 1.2284759986831482\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6373855304095974\n",
      "9\n",
      "cls val loss: 1.1912492556744312\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7389624427397017\n",
      "Save model!!!!!!!!!!!\n",
      "10\n",
      "cls val loss: 1.198676287409771\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7186124016182058\n",
      "11\n",
      "cls val loss: 1.1741403370018464\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7291283344878284\n",
      "Save model!!!!!!!!!!!\n",
      "12\n",
      "cls val loss: 1.178128989346056\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7337926405643311\n",
      "13\n",
      "cls val loss: 1.2079792554119984\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6852099131904665\n",
      "14\n",
      "cls val loss: 1.1576718530022954\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7559310295569673\n",
      "Save model!!!!!!!!!!!\n",
      "15\n",
      "cls val loss: 1.1496793182499438\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.766429623222745\n",
      "Save model!!!!!!!!!!!\n",
      "16\n",
      "cls val loss: 1.2098750443343658\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6682587050705686\n",
      "17\n",
      "cls val loss: 1.2119215576045483\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6750093053528946\n",
      "18\n",
      "cls val loss: 1.1360784359725125\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.7820880143062013\n",
      "Save model!!!!!!!!!!!\n",
      "19\n",
      "cls val loss: 1.1660355221794312\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7570029256747228\n",
      "20\n",
      "cls val loss: 1.1658466106437775\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7564365975607666\n",
      "21\n",
      "cls val loss: 1.149206828640168\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7611353164690806\n",
      "22\n",
      "cls val loss: 1.1374606892287014\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7804855998618679\n",
      "23\n",
      "cls val loss: 1.1967433784381454\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7454074032004907\n",
      "24\n",
      "cls val loss: 1.1500332384224397\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7871761611350523\n",
      "25\n",
      "cls val loss: 1.123703282281577\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8092914457896994\n",
      "Save model!!!!!!!!!!!\n",
      "26\n",
      "cls val loss: 1.1733721358230316\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.74009467102796\n",
      "27\n",
      "cls val loss: 1.162865830473153\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7743040911494956\n",
      "28\n",
      "cls val loss: 1.1458547833454178\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7796782439978204\n",
      "29\n",
      "cls val loss: 1.1660957961197358\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7471087613184789\n",
      "30\n",
      "cls val loss: 1.1688697474548615\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7619462434909705\n",
      "31\n",
      "cls val loss: 1.1520152688026428\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7532438276928148\n",
      "32\n",
      "cls val loss: 1.1615063483456531\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7266556780785597\n",
      "33\n",
      "cls val loss: 1.1647092168589672\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7607126610540887\n",
      "34\n",
      "cls val loss: 1.123682063746165\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7933652050602709\n",
      "Save model!!!!!!!!!!!\n",
      "35\n",
      "cls val loss: 1.1301666936242436\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7942099001893679\n",
      "36\n",
      "cls val loss: 1.1170419720282037\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8128022989994084\n",
      "Save model!!!!!!!!!!!\n",
      "37\n",
      "cls val loss: 1.1142305760498505\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.8042466933927311\n",
      "Save model!!!!!!!!!!!\n",
      "38\n",
      "cls val loss: 1.1371970226965755\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.778342740045666\n",
      "39\n",
      "cls val loss: 1.1060295004442513\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.8279248947359108\n",
      "Save model!!!!!!!!!!!\n",
      "40\n",
      "cls val loss: 1.108634114265442\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.796405329810715\n",
      "41\n",
      "cls val loss: 1.1295611319771732\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.8058862272566542\n",
      "42\n",
      "cls val loss: 1.1020100332168212\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8111535358045548\n",
      "Save model!!!!!!!!!!!\n",
      "43\n",
      "cls val loss: 1.134895053972681\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7786579455474409\n",
      "44\n",
      "cls val loss: 1.1183615355606538\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7909478708152422\n",
      "45\n",
      "cls val loss: 1.1065212200923138\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8212481208192484\n",
      "46\n",
      "cls val loss: 1.1383674388908478\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.832569121375635\n",
      "47\n",
      "cls val loss: 1.1004508977912995\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8244998042059185\n",
      "Save model!!!!!!!!!!!\n",
      "48\n",
      "cls val loss: 1.0999144251088062\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7907837861541247\n",
      "Save model!!!!!!!!!!!\n",
      "49\n",
      "cls val loss: 1.1209705457629928\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8133326583430854\n",
      "50\n",
      "cls val loss: 1.0822497685271573\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.83791682252703\n",
      "Save model!!!!!!!!!!!\n",
      "51\n",
      "cls val loss: 1.0877305958644454\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8299622483827644\n",
      "52\n",
      "cls val loss: 1.1009648241192462\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8191170331947241\n",
      "53\n",
      "cls val loss: 1.1118945867182262\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.823844687849856\n",
      "54\n",
      "cls val loss: 1.0674563811486026\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.8508501048079029\n",
      "Save model!!!!!!!!!!!\n",
      "55\n",
      "cls val loss: 1.1100360506988434\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8049690901482416\n",
      "56\n",
      "cls val loss: 1.077462352183928\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8473758762172451\n",
      "57\n",
      "cls val loss: 1.142546953207039\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.8047640126145164\n",
      "58\n",
      "cls val loss: 1.0668975789862942\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8651943248011549\n",
      "Save model!!!!!!!!!!!\n",
      "59\n",
      "cls val loss: 1.1552260848413032\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7314620505568864\n",
      "60\n",
      "cls val loss: 1.1001024052321193\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8352283073021612\n",
      "61\n",
      "cls val loss: 1.1085488688514893\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.837654177601158\n",
      "62\n",
      "cls val loss: 1.0786312567182335\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8643396370541594\n",
      "63\n",
      "cls val loss: 1.054631749549544\n",
      "Accuracy: 0.7108433734939759\n",
      "cls_auprc: 0.8676924065460815\n",
      "Save model!!!!!!!!!!!\n",
      "64\n",
      "cls val loss: 1.0924117435891945\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.8267874208775898\n",
      "65\n",
      "cls val loss: 1.050680307020624\n",
      "Accuracy: 0.7108433734939759\n",
      "cls_auprc: 0.8554008479682247\n",
      "Save model!!!!!!!!!!!\n",
      "66\n",
      "cls val loss: 1.0788717521242348\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8551211595014436\n",
      "67\n",
      "cls val loss: 1.0812121421457774\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8532629249173633\n",
      "68\n",
      "cls val loss: 1.102584157363478\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.8309400105503899\n",
      "69\n",
      "cls val loss: 1.0973597599799374\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.8495548122487383\n",
      "70\n",
      "cls val loss: 1.0616777115557567\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8533233081826965\n",
      "71\n",
      "cls val loss: 1.0820742005325226\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8375263170072487\n",
      "72\n",
      "cls val loss: 1.095007787985974\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8425636627872979\n",
      "73\n",
      "cls val loss: 1.1400056840425514\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7550643027609554\n",
      "74\n",
      "cls val loss: 1.114102757120707\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8212117922584768\n",
      "75\n",
      "cls val loss: 1.1623091532523373\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7710628421437925\n",
      "76\n",
      "cls val loss: 1.128009357366217\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7873524165697857\n",
      "77\n",
      "cls val loss: 1.1608916506709823\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.783011285834328\n",
      "78\n",
      "cls val loss: 1.1409557583820389\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7966865667044242\n",
      "79\n",
      "cls val loss: 1.1005645983190422\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.8357881684369474\n",
      "80\n",
      "cls val loss: 1.1030204102217434\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.809976658745861\n",
      "81\n",
      "cls val loss: 1.1392249228006386\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7530513164609511\n",
      "82\n",
      "cls val loss: 1.1073137378118125\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8433508353412852\n",
      "83\n",
      "cls val loss: 1.1038287045007729\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.8273315283501005\n",
      "84\n",
      "cls val loss: 1.1099314876349575\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.8277877277598487\n",
      "85\n",
      "cls val loss: 1.0659252843224858\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.856201556855612\n",
      "86\n",
      "cls val loss: 1.0841095174651547\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.844801356605974\n",
      "87\n",
      "cls val loss: 1.0945779386773167\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.830012259676985\n",
      "88\n",
      "cls val loss: 1.0605470480689083\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8680090990328417\n",
      "89\n",
      "cls val loss: 1.084252881716533\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8425965752128695\n",
      "90\n",
      "cls val loss: 1.1004212039062775\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8324359013457153\n",
      "91\n",
      "cls val loss: 1.1072096286049808\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8535240602963649\n",
      "92\n",
      "cls val loss: 1.0923650745885918\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8352470408304893\n",
      "93\n",
      "cls val loss: 1.1252429456595916\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7800580795455695\n",
      "94\n",
      "cls val loss: 1.0612519361886634\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8584077600155406\n",
      "95\n",
      "cls val loss: 1.0527548732527767\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.857534567201454\n",
      "96\n",
      "cls val loss: 1.0989729338381664\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8292385947803104\n",
      "97\n",
      "cls val loss: 1.083756636424237\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8483080747743103\n",
      "98\n",
      "cls val loss: 1.0887612973351077\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8482190012436455\n",
      "99\n",
      "cls val loss: 1.0658579734434563\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8456486633720776\n",
      "100\n",
      "cls val loss: 1.1021817010569286\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8380275843886158\n",
      "101\n",
      "cls val loss: 1.0807560840284969\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8270028870959446\n",
      "EarlyStopping\n",
      "Class 0 AUROC: 0.9538461538461538\n",
      "Class 1 AUROC: 0.8427895981087471\n",
      "Class 2 AUROC: 0.8157276995305165\n",
      "Class 3 AUROC: 0.8092399403874814\n",
      "Accuracy: 0.7108433734939759\n",
      "Precision: [0.69230769 0.80555556 0.41666667 0.72727273]\n",
      "Recall: [0.75       0.76315789 0.625      0.64      ]\n",
      "f1: [0.72       0.78378378 0.5        0.68085106]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Patients data is successfully written into Excel File\n",
      "Validation acc: 0.8554008479682247\n",
      "validation error: 0.2891566265060241\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "0\n",
      "cls val loss: 1.2794896572469228\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5997290978196205\n",
      "Save model!!!!!!!!!!!\n",
      "1\n",
      "cls val loss: 1.278085042913276\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.6199506474800986\n",
      "Save model!!!!!!!!!!!\n",
      "2\n",
      "cls val loss: 1.2492998436272862\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.6791005202370938\n",
      "Save model!!!!!!!!!!!\n",
      "3\n",
      "cls val loss: 1.2393949146730354\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.6711461225799349\n",
      "Save model!!!!!!!!!!!\n",
      "4\n",
      "cls val loss: 1.2103028117892254\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.690339069135119\n",
      "Save model!!!!!!!!!!!\n",
      "5\n",
      "cls val loss: 1.1834481846855347\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7180516204697392\n",
      "Save model!!!!!!!!!!!\n",
      "6\n",
      "cls val loss: 1.1845461137323494\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7147827664867119\n",
      "7\n",
      "cls val loss: 1.17634927795594\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7431730416154312\n",
      "Save model!!!!!!!!!!!\n",
      "8\n",
      "cls val loss: 1.1835872581206173\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7102609702450903\n",
      "9\n",
      "cls val loss: 1.1708856885691723\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7316343318621551\n",
      "Save model!!!!!!!!!!!\n",
      "10\n",
      "cls val loss: 1.1594955971442074\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7245940496158495\n",
      "Save model!!!!!!!!!!!\n",
      "11\n",
      "cls val loss: 1.1618309085627636\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.729625744911574\n",
      "12\n",
      "cls val loss: 1.1628883595926216\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7122477193360288\n",
      "13\n",
      "cls val loss: 1.1555867439293\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.735887227639722\n",
      "Save model!!!!!!!!!!!\n",
      "14\n",
      "cls val loss: 1.1487913835479553\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7466408165459291\n",
      "Save model!!!!!!!!!!!\n",
      "15\n",
      "cls val loss: 1.1501133815351738\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7453352443626052\n",
      "16\n",
      "cls val loss: 1.1352439809994526\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7406094276831343\n",
      "Save model!!!!!!!!!!!\n",
      "17\n",
      "cls val loss: 1.172608887574759\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7439791438361864\n",
      "18\n",
      "cls val loss: 1.169607684554824\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7359001407538794\n",
      "19\n",
      "cls val loss: 1.1536281769534191\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7274909704228641\n",
      "20\n",
      "cls val loss: 1.1311597967722329\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7682619416854177\n",
      "Save model!!!!!!!!!!!\n",
      "21\n",
      "cls val loss: 1.1273159952048797\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7539512310738552\n",
      "Save model!!!!!!!!!!!\n",
      "22\n",
      "cls val loss: 1.1191401129745575\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7681084109355429\n",
      "Save model!!!!!!!!!!!\n",
      "23\n",
      "cls val loss: 1.1375820478761052\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.7588253164309258\n",
      "24\n",
      "cls val loss: 1.1229830233447522\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.771211334845231\n",
      "25\n",
      "cls val loss: 1.1255094186369194\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.7640966788860255\n",
      "26\n",
      "cls val loss: 1.1130572105028542\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.7757110242568246\n",
      "Save model!!!!!!!!!!!\n",
      "27\n",
      "cls val loss: 1.1362219969910312\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7517563831946905\n",
      "28\n",
      "cls val loss: 1.1065061623791614\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.7734692178700492\n",
      "Save model!!!!!!!!!!!\n",
      "29\n",
      "cls val loss: 1.1211771476699646\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.770177368657217\n",
      "30\n",
      "cls val loss: 1.1406710313027164\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.758487116183302\n",
      "31\n",
      "cls val loss: 1.1699490827250194\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7552934832448679\n",
      "32\n",
      "cls val loss: 1.11493062757584\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7807788058354853\n",
      "33\n",
      "cls val loss: 1.1611087092434067\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7730655615728961\n",
      "34\n",
      "cls val loss: 1.1078872429319175\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7959191978414482\n",
      "35\n",
      "cls val loss: 1.126322776438242\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7932491970901361\n",
      "36\n",
      "cls val loss: 1.1053950169000282\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.7815721184394333\n",
      "Save model!!!!!!!!!!!\n",
      "37\n",
      "cls val loss: 1.1288169026374817\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7953825031886705\n",
      "38\n",
      "cls val loss: 1.2777563649487782\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.7434519332864145\n",
      "39\n",
      "cls val loss: 1.2166477628501065\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7899321958335527\n",
      "40\n",
      "cls val loss: 1.0998898708676716\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8044584141268976\n",
      "Save model!!!!!!!!!!!\n",
      "41\n",
      "cls val loss: 1.0851507574678905\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8293331951207263\n",
      "Save model!!!!!!!!!!!\n",
      "42\n",
      "cls val loss: 1.0805272237364068\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.8336599052536726\n",
      "Save model!!!!!!!!!!!\n",
      "43\n",
      "cls val loss: 1.0886377433696426\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8216109744452542\n",
      "44\n",
      "cls val loss: 1.0701254699603622\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8416582704282218\n",
      "Save model!!!!!!!!!!!\n",
      "45\n",
      "cls val loss: 1.0681596915405918\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8544376487611062\n",
      "Save model!!!!!!!!!!!\n",
      "46\n",
      "cls val loss: 1.0523861251681683\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.8409461623488899\n",
      "Save model!!!!!!!!!!!\n",
      "47\n",
      "cls val loss: 1.1262852140219815\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7962093215275985\n",
      "48\n",
      "cls val loss: 1.0864131709179246\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8152557768659155\n",
      "49\n",
      "cls val loss: 1.0507928125829582\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.842235317768645\n",
      "Save model!!!!!!!!!!!\n",
      "50\n",
      "cls val loss: 1.0538180786443043\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.837093040390704\n",
      "51\n",
      "cls val loss: 1.0685294327965702\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.835152310435462\n",
      "52\n",
      "cls val loss: 1.0740691782480263\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.838969472723102\n",
      "53\n",
      "cls val loss: 1.0613808933510838\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8515911321863707\n",
      "54\n",
      "cls val loss: 1.0836539297218781\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8503658197027254\n",
      "55\n",
      "cls val loss: 1.060237665492368\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.84025394970769\n",
      "56\n",
      "cls val loss: 1.0509001260780426\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.8382533239806018\n",
      "57\n",
      "cls val loss: 1.0483404362058064\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8770175975062076\n",
      "Save model!!!!!!!!!!!\n",
      "58\n",
      "cls val loss: 1.0415061482463974\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8655840065667534\n",
      "Save model!!!!!!!!!!!\n",
      "59\n",
      "cls val loss: 1.0531990894352097\n",
      "Accuracy: 0.7108433734939759\n",
      "cls_auprc: 0.8564900739242569\n",
      "60\n",
      "cls val loss: 1.0585910713816264\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8400664416453607\n",
      "61\n",
      "cls val loss: 1.045484124896038\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8609709297990712\n",
      "62\n",
      "cls val loss: 1.0905320565384555\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8314469253283074\n",
      "63\n",
      "cls val loss: 1.0549541898520596\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8321446754808173\n",
      "64\n",
      "cls val loss: 1.0479587000536632\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8579972329700907\n",
      "65\n",
      "cls val loss: 1.0645248767841293\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8659934450183006\n",
      "66\n",
      "cls val loss: 1.0261881969061242\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.892876285355419\n",
      "Save model!!!!!!!!!!!\n",
      "67\n",
      "cls val loss: 1.0225040790546371\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8735872519451566\n",
      "Save model!!!!!!!!!!!\n",
      "68\n",
      "cls val loss: 1.0400292140891754\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.864921092537006\n",
      "69\n",
      "cls val loss: 1.0349493874124733\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8642969383939972\n",
      "70\n",
      "cls val loss: 1.0631802642201802\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8349835268903393\n",
      "71\n",
      "cls val loss: 1.0451127197369035\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8593063529109698\n",
      "72\n",
      "cls val loss: 1.0501164477991771\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.857926780390083\n",
      "73\n",
      "cls val loss: 1.0822544399514256\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8404556963437891\n",
      "74\n",
      "cls val loss: 1.0421639135084957\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8496785968575198\n",
      "75\n",
      "cls val loss: 1.0466998793992652\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8499025978688308\n",
      "76\n",
      "cls val loss: 1.0458147655050438\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8479394262338351\n",
      "77\n",
      "cls val loss: 1.0416107572704913\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.852059399184897\n",
      "78\n",
      "cls val loss: 1.0639693241521537\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8450446231016906\n",
      "79\n",
      "cls val loss: 1.055497052439724\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8737683193255219\n",
      "80\n",
      "cls val loss: 1.0268417453191367\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8666129752563774\n",
      "81\n",
      "cls val loss: 1.0542438619108085\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.840917159400373\n",
      "82\n",
      "cls val loss: 1.0588898565395768\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8626599592238824\n",
      "83\n",
      "cls val loss: 1.0375238046588668\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8503299575731376\n",
      "84\n",
      "cls val loss: 1.040209621550089\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.8386293064355597\n",
      "85\n",
      "cls val loss: 1.0464511463441044\n",
      "Accuracy: 0.7108433734939759\n",
      "cls_auprc: 0.8402117568427251\n",
      "86\n",
      "cls val loss: 1.1019403309707183\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.8606719866653203\n",
      "87\n",
      "cls val loss: 1.038782752421965\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8605065058256915\n",
      "88\n",
      "cls val loss: 1.039194442421557\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8643194300779768\n",
      "89\n",
      "cls val loss: 1.016105471605278\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.884356436239631\n",
      "Save model!!!!!!!!!!!\n",
      "90\n",
      "cls val loss: 1.032789669841169\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8623569601107833\n",
      "91\n",
      "cls val loss: 1.060733449028199\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8361677351029227\n",
      "92\n",
      "cls val loss: 1.0457168479999863\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8555803174900036\n",
      "93\n",
      "cls val loss: 1.0680393985955112\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8347346364256247\n",
      "94\n",
      "cls val loss: 1.0441853432770234\n",
      "Accuracy: 0.6987951807228916\n",
      "cls_auprc: 0.8334251760933846\n",
      "95\n",
      "cls val loss: 1.0552060934434455\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8459519530018211\n",
      "96\n",
      "cls val loss: 1.0768403604806187\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8324363404640673\n",
      "97\n",
      "cls val loss: 1.0413167491016617\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.8430641269042184\n",
      "98\n",
      "cls val loss: 1.0423411439700299\n",
      "Accuracy: 0.6746987951807228\n",
      "cls_auprc: 0.861267179500463\n",
      "99\n",
      "cls val loss: 1.0387187901749668\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8520136890447785\n",
      "100\n",
      "cls val loss: 1.0387040003236518\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8498234186653155\n",
      "101\n",
      "cls val loss: 1.0525551905114967\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8587255332165848\n",
      "102\n",
      "cls val loss: 1.0430471516517272\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8519983252464203\n",
      "103\n",
      "cls val loss: 1.0483954563198319\n",
      "Accuracy: 0.6506024096385542\n",
      "cls_auprc: 0.8501728269552515\n",
      "104\n",
      "cls val loss: 1.0415806425623146\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.853276109114953\n",
      "105\n",
      "cls val loss: 1.0523077637316234\n",
      "Accuracy: 0.7108433734939759\n",
      "cls_auprc: 0.8230200539444388\n",
      "106\n",
      "cls val loss: 1.0674957352948475\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8414829305834037\n",
      "107\n",
      "cls val loss: 1.1216612688030105\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.8520330448244374\n",
      "108\n",
      "cls val loss: 1.0455537431211357\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8676107359856261\n",
      "109\n",
      "cls val loss: 1.0392955814499454\n",
      "Accuracy: 0.6867469879518072\n",
      "cls_auprc: 0.87551756661183\n",
      "110\n",
      "cls val loss: 1.0494427831776172\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8524016522354825\n",
      "111\n",
      "cls val loss: 1.052988413586674\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8527616954413257\n",
      "112\n",
      "cls val loss: 1.0614289619836463\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8425418019227123\n",
      "113\n",
      "cls val loss: 1.0549651642879807\n",
      "Accuracy: 0.6385542168674698\n",
      "cls_auprc: 0.8649906842481896\n",
      "114\n",
      "cls val loss: 1.0521947597882835\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8644177337779744\n",
      "115\n",
      "cls val loss: 1.0559574430247387\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.8619840259573233\n",
      "116\n",
      "cls val loss: 1.0481737507394997\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.8538939590379113\n",
      "117\n",
      "cls val loss: 1.0620982927012157\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.8398862538308738\n",
      "118\n",
      "cls val loss: 1.0727119654057973\n",
      "Accuracy: 0.6626506024096386\n",
      "cls_auprc: 0.8184442246197061\n",
      "119\n",
      "cls val loss: 1.0352103128490677\n",
      "Accuracy: 0.6987951807228916\n",
      "cls_auprc: 0.8382459004320448\n",
      "EarlyStopping\n",
      "Class 0 AUROC: 0.9285714285714286\n",
      "Class 1 AUROC: 0.8522458628841608\n",
      "Class 2 AUROC: 0.9354460093896713\n",
      "Class 3 AUROC: 0.8211624441132638\n",
      "Accuracy: 0.6867469879518072\n",
      "Precision: [0.76923077 0.72222222 0.75       0.54545455]\n",
      "Recall: [0.71428571 0.74285714 0.6        0.63157895]\n",
      "f1: [0.74074074 0.73239437 0.66666667 0.58536585]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "Patients data is successfully written into Excel File\n",
      "Validation acc: 0.884356436239631\n",
      "validation error: 0.3132530120481928\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "0\n",
      "cls val loss: 1.286231749747173\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5622553168224037\n",
      "Save model!!!!!!!!!!!\n",
      "1\n",
      "cls val loss: 1.2733229226376637\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.572174758791898\n",
      "Save model!!!!!!!!!!!\n",
      "2\n",
      "cls val loss: 1.2687766688415802\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5688954066616098\n",
      "Save model!!!!!!!!!!!\n",
      "3\n",
      "cls val loss: 1.269316210086087\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.5816502683438604\n",
      "4\n",
      "cls val loss: 1.250272833439241\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6403536067595151\n",
      "Save model!!!!!!!!!!!\n",
      "5\n",
      "cls val loss: 1.2378474732479416\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.628584210315433\n",
      "Save model!!!!!!!!!!!\n",
      "6\n",
      "cls val loss: 1.2200996078640582\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6600649715524787\n",
      "Save model!!!!!!!!!!!\n",
      "7\n",
      "cls val loss: 1.214864280568548\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6583448978943238\n",
      "Save model!!!!!!!!!!!\n",
      "8\n",
      "cls val loss: 1.2130779264921165\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6475982279343254\n",
      "Save model!!!!!!!!!!!\n",
      "9\n",
      "cls val loss: 1.2579909168094037\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6403632998905453\n",
      "10\n",
      "cls val loss: 1.1931219144039844\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.663369560786869\n",
      "Save model!!!!!!!!!!!\n",
      "11\n",
      "cls val loss: 1.1971201975661587\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.657156314918637\n",
      "12\n",
      "cls val loss: 1.1943350872361516\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6645508090505683\n",
      "13\n",
      "cls val loss: 1.2162916107350086\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6801583543567976\n",
      "14\n",
      "cls val loss: 1.1902243997677262\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.6669443219736259\n",
      "Save model!!!!!!!!!!!\n",
      "15\n",
      "cls val loss: 1.2064007513494377\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.6533980919629656\n",
      "16\n",
      "cls val loss: 1.189657736255462\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6671880895613069\n",
      "Save model!!!!!!!!!!!\n",
      "17\n",
      "cls val loss: 1.1877320983323707\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.6570153422501904\n",
      "Save model!!!!!!!!!!!\n",
      "18\n",
      "cls val loss: 1.1912993731268917\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6928128759755774\n",
      "19\n",
      "cls val loss: 1.1737778050353729\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6862219450412193\n",
      "Save model!!!!!!!!!!!\n",
      "20\n",
      "cls val loss: 1.1730693097574165\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7096386059684423\n",
      "Save model!!!!!!!!!!!\n",
      "21\n",
      "cls val loss: 1.187799951398229\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6828283942062884\n",
      "22\n",
      "cls val loss: 1.209612405443766\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6953632908780607\n",
      "23\n",
      "cls val loss: 1.1739473529608853\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7078851376670292\n",
      "24\n",
      "cls val loss: 1.1796504826430816\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6789159927019961\n",
      "25\n",
      "cls val loss: 1.2060698407242096\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7139379499324134\n",
      "26\n",
      "cls val loss: 1.1687300621745098\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7311893118663458\n",
      "Save model!!!!!!!!!!!\n",
      "27\n",
      "cls val loss: 1.2027115469955536\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7168411431206373\n",
      "28\n",
      "cls val loss: 1.1803289587239185\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.719780851819728\n",
      "29\n",
      "cls val loss: 1.189809506916138\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7146122966008797\n",
      "30\n",
      "cls val loss: 1.1647414328104042\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7409946259318917\n",
      "Save model!!!!!!!!!!!\n",
      "31\n",
      "cls val loss: 1.1783661059586399\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7318461800471139\n",
      "32\n",
      "cls val loss: 1.1623422740453697\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7336904243608509\n",
      "Save model!!!!!!!!!!!\n",
      "33\n",
      "cls val loss: 1.2649138670369804\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.711096170719581\n",
      "34\n",
      "cls val loss: 1.1813747164714767\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7406052623025019\n",
      "35\n",
      "cls val loss: 1.163501804851624\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7437430815684204\n",
      "36\n",
      "cls val loss: 1.1532148410038776\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7448818799184421\n",
      "Save model!!!!!!!!!!!\n",
      "37\n",
      "cls val loss: 1.1736004962978592\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7461773764956658\n",
      "38\n",
      "cls val loss: 1.168515647750303\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7492858579224437\n",
      "39\n",
      "cls val loss: 1.1720295921865715\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7430191260116048\n",
      "40\n",
      "cls val loss: 1.1922891879656228\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7419274721513773\n",
      "41\n",
      "cls val loss: 1.136623212371964\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7601229798624755\n",
      "Save model!!!!!!!!!!!\n",
      "42\n",
      "cls val loss: 1.1455651514501457\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7731145319530883\n",
      "43\n",
      "cls val loss: 1.161929058023246\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7521176424452288\n",
      "44\n",
      "cls val loss: 1.1449934639126422\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7774501207398381\n",
      "45\n",
      "cls val loss: 1.1592056313192989\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7631351128117391\n",
      "46\n",
      "cls val loss: 1.1371838134455394\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7796136767434119\n",
      "47\n",
      "cls val loss: 1.136527258229543\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7697707169733432\n",
      "Save model!!!!!!!!!!!\n",
      "48\n",
      "cls val loss: 1.1349622255348297\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7616321438691831\n",
      "Save model!!!!!!!!!!!\n",
      "49\n",
      "cls val loss: 1.1599297545042382\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7687508805167496\n",
      "50\n",
      "cls val loss: 1.1055869934070541\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7838767198547874\n",
      "Save model!!!!!!!!!!!\n",
      "51\n",
      "cls val loss: 1.0802571780710335\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.807198712490105\n",
      "Save model!!!!!!!!!!!\n",
      "52\n",
      "cls val loss: 1.1124908241880946\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7686027302651885\n",
      "53\n",
      "cls val loss: 1.1009054923632058\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.790904807368255\n",
      "54\n",
      "cls val loss: 1.1061108801738326\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7844028849645213\n",
      "55\n",
      "cls val loss: 1.1211831519402653\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7649614140129082\n",
      "56\n",
      "cls val loss: 1.0955001970371567\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7929870099796705\n",
      "57\n",
      "cls val loss: 1.083652382873627\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7944605153908937\n",
      "58\n",
      "cls val loss: 1.111589783645538\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7865266921891725\n",
      "59\n",
      "cls val loss: 1.1107736840305558\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.775867480397047\n",
      "60\n",
      "cls val loss: 1.1406908746225288\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.773726623517284\n",
      "61\n",
      "cls val loss: 1.1510444570736713\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.76604792713745\n",
      "62\n",
      "cls val loss: 1.1094294448932969\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7790117453139973\n",
      "63\n",
      "cls val loss: 1.108810440603509\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7726318687202494\n",
      "64\n",
      "cls val loss: 1.1005968523312764\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7884666479991131\n",
      "65\n",
      "cls val loss: 1.0930726973407239\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7803132764797065\n",
      "66\n",
      "cls val loss: 1.1067289185811238\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7763263253070776\n",
      "67\n",
      "cls val loss: 1.0818775841988713\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7973806600320918\n",
      "68\n",
      "cls val loss: 1.1289008238229408\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7828104966946299\n",
      "69\n",
      "cls val loss: 1.108331968985408\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7558972752663586\n",
      "70\n",
      "cls val loss: 1.1002452466861312\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7936142451423184\n",
      "71\n",
      "cls val loss: 1.1201075660177024\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7811019861115166\n",
      "72\n",
      "cls val loss: 1.1454403781029114\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7763544767932359\n",
      "73\n",
      "cls val loss: 1.2368122604956109\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7543230115174951\n",
      "74\n",
      "cls val loss: 1.136091560484415\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7662136864425413\n",
      "75\n",
      "cls val loss: 1.1162322874528816\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7726672898774571\n",
      "76\n",
      "cls val loss: 1.1168598087437183\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7679503350121716\n",
      "77\n",
      "cls val loss: 1.1243782740041435\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7657918663080607\n",
      "78\n",
      "cls val loss: 1.1066112561398243\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.77988113230619\n",
      "79\n",
      "cls val loss: 1.1058864622230988\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7704977598412238\n",
      "80\n",
      "cls val loss: 1.0915366332215\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7909945170827257\n",
      "81\n",
      "cls val loss: 1.0970404313271305\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7875435919676599\n",
      "82\n",
      "cls val loss: 1.1363703572606465\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7682914368442868\n",
      "83\n",
      "cls val loss: 1.0968987913016814\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7869541186112221\n",
      "84\n",
      "cls val loss: 1.0955327648714364\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7869998136260166\n",
      "85\n",
      "cls val loss: 1.101465200803366\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7834905639460383\n",
      "86\n",
      "cls val loss: 1.0912530407848129\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.789411315092144\n",
      "87\n",
      "cls val loss: 1.1295624411249736\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7691989189042225\n",
      "88\n",
      "cls val loss: 1.1211803325687546\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7766769400443876\n",
      "89\n",
      "cls val loss: 1.0929789966847523\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7905762059620683\n",
      "90\n",
      "cls val loss: 1.098775542644133\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7875500440396269\n",
      "91\n",
      "cls val loss: 1.0896641841853958\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7658518870154922\n",
      "92\n",
      "cls val loss: 1.0870147354631539\n",
      "Accuracy: 0.5903614457831325\n",
      "cls_auprc: 0.7804859375335335\n",
      "93\n",
      "cls val loss: 1.1125393969466888\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7673198358366394\n",
      "94\n",
      "cls val loss: 1.1105573227606624\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7722559122080509\n",
      "95\n",
      "cls val loss: 1.1046840419252235\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7960808032445215\n",
      "96\n",
      "cls val loss: 1.0964124511523419\n",
      "Accuracy: 0.6024096385542169\n",
      "cls_auprc: 0.7778764554938428\n",
      "97\n",
      "cls val loss: 1.1383799774100982\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7559902797794396\n",
      "98\n",
      "cls val loss: 1.087775629687022\n",
      "Accuracy: 0.6265060240963856\n",
      "cls_auprc: 0.7675516054911016\n",
      "99\n",
      "cls val loss: 1.118046017296343\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7604248078774256\n",
      "100\n",
      "cls val loss: 1.0873670326658043\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7818650152538817\n",
      "101\n",
      "cls val loss: 1.0861048224460648\n",
      "Accuracy: 0.6144578313253012\n",
      "cls_auprc: 0.7835869337925887\n",
      "EarlyStopping\n",
      "Class 0 AUROC: 0.8758241758241758\n",
      "Class 1 AUROC: 0.801418439716312\n",
      "Class 2 AUROC: 0.8309859154929577\n",
      "Class 3 AUROC: 0.7205663189269746\n",
      "Accuracy: 0.5783132530120482\n",
      "Precision: [0.53846154 0.80555556 0.33333333 0.36363636]\n",
      "Recall: [0.63636364 0.58       0.8        0.47058824]\n",
      "f1: [0.58333333 0.6744186  0.47058824 0.41025641]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "Patients data is successfully written into Excel File\n",
      "Validation acc: 0.807198712490105\n",
      "validation error: 0.42168674698795183\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "0\n",
      "cls val loss: 1.2723423271294099\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5765567505526705\n",
      "Save model!!!!!!!!!!!\n",
      "1\n",
      "cls val loss: 1.276865960603737\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5782018516468819\n",
      "2\n",
      "cls val loss: 1.2696347473615623\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5834529414236818\n",
      "Save model!!!!!!!!!!!\n",
      "3\n",
      "cls val loss: 1.264722890882607\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.577926660602152\n",
      "Save model!!!!!!!!!!!\n",
      "4\n",
      "cls val loss: 1.265325106052031\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5832126164865276\n",
      "5\n",
      "cls val loss: 1.2653608099523797\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.577582238904559\n",
      "6\n",
      "cls val loss: 1.2632866975772812\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.5833888131581161\n",
      "Save model!!!!!!!!!!!\n",
      "7\n",
      "cls val loss: 1.2656727038234112\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.5790023130692452\n",
      "8\n",
      "cls val loss: 1.2574267918805042\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.5923181885941089\n",
      "Save model!!!!!!!!!!!\n",
      "9\n",
      "cls val loss: 1.2580479211117848\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.5993682225914475\n",
      "10\n",
      "cls val loss: 1.2319022395524635\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6298505604410094\n",
      "Save model!!!!!!!!!!!\n",
      "11\n",
      "cls val loss: 1.228221313781049\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6313607567050705\n",
      "Save model!!!!!!!!!!!\n",
      "12\n",
      "cls val loss: 1.2289663402430981\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6137975685966544\n",
      "13\n",
      "cls val loss: 1.229634464505207\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6152087073279294\n",
      "14\n",
      "cls val loss: 1.2178801571030216\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6350715381856537\n",
      "Save model!!!!!!!!!!!\n",
      "15\n",
      "cls val loss: 1.2770877588226135\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.5929263536610004\n",
      "16\n",
      "cls val loss: 1.2125653014125595\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.6405812814386949\n",
      "Save model!!!!!!!!!!!\n",
      "17\n",
      "cls val loss: 1.3365973097732269\n",
      "Accuracy: 0.37349397590361444\n",
      "cls_auprc: 0.5827362820532423\n",
      "18\n",
      "cls val loss: 1.2180432081222534\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6310942513793558\n",
      "19\n",
      "cls val loss: 1.2331406387938075\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6280329647124329\n",
      "20\n",
      "cls val loss: 1.2155884949557751\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6432616111981105\n",
      "21\n",
      "cls val loss: 1.2360990708132824\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6396548061092882\n",
      "22\n",
      "cls val loss: 1.2174092394759857\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6643859176964155\n",
      "23\n",
      "cls val loss: 1.2137071195855198\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.6508652426193335\n",
      "24\n",
      "cls val loss: 1.2051936905068088\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.6690533194339253\n",
      "Save model!!!!!!!!!!!\n",
      "25\n",
      "cls val loss: 1.209952195724809\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6594450502099221\n",
      "26\n",
      "cls val loss: 1.2472907455570728\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.6388529655763773\n",
      "27\n",
      "cls val loss: 1.214769565915487\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6680958858449071\n",
      "28\n",
      "cls val loss: 1.215642967856074\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6419493613785016\n",
      "29\n",
      "cls val loss: 1.2119668298457043\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6716979813209002\n",
      "30\n",
      "cls val loss: 1.208484726497926\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6552682978286126\n",
      "31\n",
      "cls val loss: 1.2316613032157162\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.647058765824394\n",
      "32\n",
      "cls val loss: 1.2082063232559757\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.657950514906736\n",
      "33\n",
      "cls val loss: 1.2027420358485486\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6404444034796958\n",
      "Save model!!!!!!!!!!!\n",
      "34\n",
      "cls val loss: 1.2372394649379224\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6399154520112654\n",
      "35\n",
      "cls val loss: 1.2273719454386147\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.6592304358492699\n",
      "36\n",
      "cls val loss: 1.2465900089367326\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6475513450192533\n",
      "37\n",
      "cls val loss: 1.2190102949199906\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6747410277604523\n",
      "38\n",
      "cls val loss: 1.2717778373913593\n",
      "Accuracy: 0.3855421686746988\n",
      "cls_auprc: 0.640353183863908\n",
      "39\n",
      "cls val loss: 1.216164392161082\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.6567095003055201\n",
      "40\n",
      "cls val loss: 1.2195389730384552\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6837707722836336\n",
      "41\n",
      "cls val loss: 1.2199679311499538\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6549901624033809\n",
      "42\n",
      "cls val loss: 1.2441934612860162\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.6438025454744359\n",
      "43\n",
      "cls val loss: 1.2315241148672909\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.654012975519513\n",
      "44\n",
      "cls val loss: 1.2274733638188926\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6511512075979891\n",
      "45\n",
      "cls val loss: 1.2114693335739963\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6835746540539301\n",
      "46\n",
      "cls val loss: 1.222888243485646\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.6498992806173964\n",
      "47\n",
      "cls val loss: 1.2121070989643234\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.6759445851068222\n",
      "48\n",
      "cls val loss: 1.220252984259502\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6670581128330064\n",
      "49\n",
      "cls val loss: 1.2073026349745601\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7097481610282078\n",
      "50\n",
      "cls val loss: 1.2071388952703361\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7040228632928098\n",
      "51\n",
      "cls val loss: 1.2105348361543862\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.696734112945727\n",
      "52\n",
      "cls val loss: 1.1984871496637184\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.7175119105880514\n",
      "Save model!!!!!!!!!!!\n",
      "53\n",
      "cls val loss: 1.204876359686794\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6967739320891018\n",
      "54\n",
      "cls val loss: 1.23170741351254\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6875276550497127\n",
      "55\n",
      "cls val loss: 1.2174774444246867\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.6909801848873582\n",
      "56\n",
      "cls val loss: 1.2184654309088925\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.7019648867267716\n",
      "57\n",
      "cls val loss: 1.202922717634454\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7033110529485623\n",
      "58\n",
      "cls val loss: 1.2060855540884547\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.7122435257632647\n",
      "59\n",
      "cls val loss: 1.1975785228143256\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.719078717320426\n",
      "Save model!!!!!!!!!!!\n",
      "60\n",
      "cls val loss: 1.2078772905361221\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7191020821016351\n",
      "61\n",
      "cls val loss: 1.2379661231155854\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.6994178259449781\n",
      "62\n",
      "cls val loss: 1.2031509732625572\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7187268616521848\n",
      "63\n",
      "cls val loss: 1.184661983007408\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7255935160304084\n",
      "Save model!!!!!!!!!!!\n",
      "64\n",
      "cls val loss: 1.18647514624768\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7211812627087586\n",
      "65\n",
      "cls val loss: 1.2251782086958367\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.701096695630352\n",
      "66\n",
      "cls val loss: 1.2073449104665273\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7134511845535663\n",
      "67\n",
      "cls val loss: 1.1983061598007938\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7194296826939649\n",
      "68\n",
      "cls val loss: 1.186802066234221\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7217491414513011\n",
      "69\n",
      "cls val loss: 1.1941176853984234\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7232765237437762\n",
      "70\n",
      "cls val loss: 1.2003951166049545\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6956769091205638\n",
      "71\n",
      "cls val loss: 1.200720706617976\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7244363952146048\n",
      "72\n",
      "cls val loss: 1.188378270850124\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7195892480323254\n",
      "73\n",
      "cls val loss: 1.2052976460341949\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7047488349414838\n",
      "74\n",
      "cls val loss: 1.1962525557322674\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7180759069414335\n",
      "75\n",
      "cls val loss: 1.202610361288829\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.6976961371898662\n",
      "76\n",
      "cls val loss: 1.2184728211667164\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7096795960736405\n",
      "77\n",
      "cls val loss: 1.1919975697276104\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7190551062193281\n",
      "78\n",
      "cls val loss: 1.1960771069469223\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7106313308031991\n",
      "79\n",
      "cls val loss: 1.228805196572499\n",
      "Accuracy: 0.39759036144578314\n",
      "cls_auprc: 0.7110974292433294\n",
      "80\n",
      "cls val loss: 1.2092116051409618\n",
      "Accuracy: 0.5662650602409639\n",
      "cls_auprc: 0.67886681105804\n",
      "81\n",
      "cls val loss: 1.217005603284721\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6964507665089689\n",
      "82\n",
      "cls val loss: 1.2016990235052913\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.715214663065695\n",
      "83\n",
      "cls val loss: 1.2191179789692523\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.700418307548927\n",
      "84\n",
      "cls val loss: 1.2506711475820427\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6976306526823703\n",
      "85\n",
      "cls val loss: 1.2545576993241367\n",
      "Accuracy: 0.42168674698795183\n",
      "cls_auprc: 0.6723459054115823\n",
      "86\n",
      "cls val loss: 1.1944341164037406\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7177410452529338\n",
      "87\n",
      "cls val loss: 1.2201629022517837\n",
      "Accuracy: 0.40963855421686746\n",
      "cls_auprc: 0.7047171459835357\n",
      "88\n",
      "cls val loss: 1.185830238353775\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.718864578402079\n",
      "89\n",
      "cls val loss: 1.1941359237015965\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7232267652380937\n",
      "90\n",
      "cls val loss: 1.1839786143188018\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7249431540564983\n",
      "Save model!!!!!!!!!!!\n",
      "91\n",
      "cls val loss: 1.2115320254521198\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7225135655793286\n",
      "92\n",
      "cls val loss: 1.1956427406115704\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7222287651415611\n",
      "93\n",
      "cls val loss: 1.1898126451365918\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.72582382565827\n",
      "94\n",
      "cls val loss: 1.1969594445573277\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7285844545222754\n",
      "95\n",
      "cls val loss: 1.1946008507027683\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.731765601461436\n",
      "96\n",
      "cls val loss: 1.1741582736911544\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7343442884982233\n",
      "Save model!!!!!!!!!!!\n",
      "97\n",
      "cls val loss: 1.205630255750863\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.708769988152483\n",
      "98\n",
      "cls val loss: 1.216272260769304\n",
      "Accuracy: 0.40963855421686746\n",
      "cls_auprc: 0.7154216968784264\n",
      "99\n",
      "cls val loss: 1.201197359935347\n",
      "Accuracy: 0.5180722891566265\n",
      "cls_auprc: 0.7108883934620707\n",
      "100\n",
      "cls val loss: 1.2464323302349412\n",
      "Accuracy: 0.43373493975903615\n",
      "cls_auprc: 0.6826862790271688\n",
      "101\n",
      "cls val loss: 1.197112283074712\n",
      "Accuracy: 0.5421686746987951\n",
      "cls_auprc: 0.7245464782770058\n",
      "102\n",
      "cls val loss: 1.1678577726145825\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7622050411315212\n",
      "Save model!!!!!!!!!!!\n",
      "103\n",
      "cls val loss: 1.1806745988776886\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7421190549173743\n",
      "104\n",
      "cls val loss: 1.1744314195161842\n",
      "Accuracy: 0.5783132530120482\n",
      "cls_auprc: 0.7470809277776737\n",
      "105\n",
      "cls val loss: 1.1921073413756957\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7387395289249561\n",
      "106\n",
      "cls val loss: 1.2023127588881068\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7261262089409734\n",
      "107\n",
      "cls val loss: 1.1866078312138477\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7302176509163373\n",
      "108\n",
      "cls val loss: 1.2571148125522107\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.6877726217913487\n",
      "109\n",
      "cls val loss: 1.180969708655254\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7479334388957983\n",
      "110\n",
      "cls val loss: 1.1797599296971977\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7597404262006192\n",
      "111\n",
      "cls val loss: 1.183115576405123\n",
      "Accuracy: 0.5542168674698795\n",
      "cls_auprc: 0.7331321684734978\n",
      "112\n",
      "cls val loss: 1.1760688862168645\n",
      "Accuracy: 0.4939759036144578\n",
      "cls_auprc: 0.7526196582063612\n",
      "113\n",
      "cls val loss: 1.159619700477784\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7499153680319767\n",
      "Save model!!!!!!!!!!!\n",
      "114\n",
      "cls val loss: 1.18459757336651\n",
      "Accuracy: 0.5301204819277109\n",
      "cls_auprc: 0.7357570852894644\n",
      "115\n",
      "cls val loss: 1.1925849914550781\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7234754311950135\n",
      "116\n",
      "cls val loss: 1.196587071361312\n",
      "Accuracy: 0.4578313253012048\n",
      "cls_auprc: 0.7268692850408291\n",
      "117\n",
      "cls val loss: 1.1929390179105552\n",
      "Accuracy: 0.4819277108433735\n",
      "cls_auprc: 0.7271530497994707\n",
      "118\n",
      "cls val loss: 1.1837324176926212\n",
      "Accuracy: 0.46987951807228917\n",
      "cls_auprc: 0.744177400107803\n",
      "119\n",
      "cls val loss: 1.2203025645520313\n",
      "Accuracy: 0.4457831325301205\n",
      "cls_auprc: 0.7247760337176323\n",
      "120\n",
      "cls val loss: 1.225872427584177\n",
      "Accuracy: 0.39759036144578314\n",
      "cls_auprc: 0.7188532289696827\n",
      "121\n",
      "cls val loss: 1.182022988078106\n",
      "Accuracy: 0.5060240963855421\n",
      "cls_auprc: 0.7566748222863586\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "precisions = []\n",
    "y_real = []\n",
    "y_probs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "mean_recall = np.linspace(0,1,100)\n",
    "tprs = {i: [] for i in range(4)}\n",
    "aucs = {i: [] for i in range(4)}\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kf.split(train_x, train_y)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    model_name = './model/CMS_0307CV7_fold'+str(fold)+'_clam_checkpoint.pt'\n",
    "    train_fold = torch.utils.data.Subset(train_data, train_ids)\n",
    "    valid_fold = torch.utils.data.Subset(train_data, valid_ids)\n",
    "\n",
    "    train_loader = DataLoader(train_fold, batch_size=1, shuffle = True)\n",
    "    valid_loader = DataLoader(valid_fold, batch_size=1)\n",
    "    \n",
    "    model = Attention()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00008, betas=(0.9, 0.999), weight_decay=0.001)\n",
    "\n",
    "    writer = None\n",
    "    early_stopping = EarlyStopping(patience=30, stop_epoch=100, verbose=True)\n",
    "\n",
    "    results_dir = '/home/ldap_howard/script/'\n",
    "    cur = 'model'\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        print(epoch)\n",
    "        train_epoch_loss = train_loop(epoch, model, train_loader, optimizer, 4, writer, loss_fn)\n",
    "        valid_epoch_loss, stop = validate(model_name, epoch, model, valid_loader, 4,\n",
    "                                early_stopping, writer, loss_fn, results_dir)\n",
    "        \n",
    "        train_loss.append(train_epoch_loss)\n",
    "        valid_loss.append(valid_epoch_loss)\n",
    "\n",
    "        if stop:\n",
    "            break\n",
    "    \n",
    "    if early_stopping:\n",
    "        print(\"EarlyStopping\")\n",
    "        model.load_state_dict(torch.load(os.path.join(results_dir, model_name))) #\"s_{}_checkpoint.pt\".format(cur))))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), os.path.join(results_dir, model_name)) #\"s_{}_{}_checkpoint.pt\".format(cur)))\n",
    "\n",
    "    _, cls_val_error, cls_val_auc, cls_labels, cls_probs = summary(model, valid_loader, 4, fold)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(4):\n",
    "        fpr[i], tpr[i], _ = roc_curve(cls_labels[:, i], cls_probs[:, i])\n",
    "        roc_auc[i] = calc_auc(fpr[i], tpr[i])\n",
    "        tprs[i].append(np.interp(mean_fpr, fpr[i], tpr[i]))\n",
    "        tprs[i][-1][0] = 0.0\n",
    "        aucs[i].append(roc_auc[i])\n",
    "\n",
    "    i=i+1\n",
    "    logging.info('Cls Val error: {:.4f}, Cls ROC AUC: {:.4f}'.format(cls_val_error, cls_val_auc))\n",
    "    print(\"Validation acc: \" + str(cls_val_auc))\n",
    "    print(\"validation error: \" + str(cls_val_error))\n",
    "\n",
    "    #plot_loss_curve(train_loss, valid_loss, fold)\n",
    "\n",
    "#colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"red\"])\n",
    "for i in range(4):\n",
    "    mean_tpr = np.mean(tprs[i], axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = calc_auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs[i])\n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr,\n",
    "             label=r'Mean ROC of class {0} (area = {1:0.2f} $\\pm$ {2:0.2f})'\n",
    "             ''.format(i, mean_auc, std_auc), lw=2, alpha=0.8)\n",
    "\n",
    "    std_tpr = np.std(tprs[i], axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, alpha=0.2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", alpha=0.8)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize = 20)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize = 20)\n",
    "plt.title(\"ROC curves\", fontsize = 20)\n",
    "plt.legend(loc=\"lower right\", fontsize = 18)\n",
    "plt.savefig('/home/ldap_howard/script/summary/attention_hover/auroc_clam.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.path = '/ORCA_lake/TCGA-COAD/feature/CRC_resnet0307/'\n",
    "        self.path_c = '/ORCA_lake/TCGA-COAD/hovernet_kmeans/CRC_0307_MI2N/'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.path, self.x[idx]+'.npy')\n",
    "        count_path = os.path.join(self.path_c, self.x[idx]+'.npy')\n",
    "\n",
    "        return image_path, count_path, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_excel('/home/ldap_howard/script/CRC_CMS.xlsx',sheet_name = 'CMS_0604')\n",
    "test_x = test_dataset['Patients'].values\n",
    "test_y = test_dataset['status'].values\n",
    "test_data = SimpleDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (layer1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (attention_V): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (attention_U): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (attention_weights): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1028, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       "  (instance_loss): CrossEntropyLoss()\n",
       "  (fc_c1): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc_X): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=4, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Attention().to(device)\n",
    "model.load_state_dict(torch.load('/home/ldap_howard/script/model/CMS_0307CV6_fold2_clam_checkpoint.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 AUROC: 0.9300460223537146\n",
      "Class 1 AUROC: 0.8932173504173034\n",
      "Class 2 AUROC: 0.9301029962546817\n",
      "Class 3 AUROC: 0.8773024361259656\n",
      "Accuracy: 0.75\n",
      "Precision: [0.83076923 0.79558011 0.83333333 0.58181818]\n",
      "Recall: [0.84375    0.74611399 0.73529412 0.7032967 ]\n",
      "f1: [0.8372093  0.77005348 0.78125    0.63681592]\n",
      "Patients data is successfully written into Excel File\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({},\n",
       " 0.25,\n",
       " 0.9076672012879163,\n",
       " array([0., 3., 2., 1., 1., 0., 1., 2., 1., 1., 1., 3., 2., 2., 1., 0., 1.,\n",
       "        2., 1., 1., 0., 0., 2., 1., 3., 0., 0., 1., 0., 3., 1., 1., 2., 1.,\n",
       "        0., 1., 3., 2., 1., 1., 0., 1., 1., 3., 1., 2., 1., 0., 0., 2., 2.,\n",
       "        1., 1., 1., 1., 0., 0., 2., 1., 1., 3., 3., 3., 1., 3., 1., 1., 0.,\n",
       "        0., 1., 0., 3., 2., 1., 1., 1., 1., 3., 1., 2., 2., 2., 1., 1., 2.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 2., 1., 2., 1., 3., 3., 1., 2., 1., 1.,\n",
       "        1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 3., 3., 3., 3., 1., 3., 0.,\n",
       "        0., 2., 0., 3., 1., 1., 3., 0., 1., 3., 2., 1., 3., 3., 1., 1., 0.,\n",
       "        3., 3., 2., 3., 3., 1., 3., 3., 2., 3., 1., 3., 3., 2., 3., 1., 1.,\n",
       "        0., 1., 3., 1., 3., 1., 2., 3., 3., 3., 2., 1., 3., 1., 2., 1., 1.,\n",
       "        3., 0., 3., 0., 1., 3., 1., 0., 1., 3., 2., 3., 0., 1., 3., 1., 2.,\n",
       "        0., 1., 1., 2., 1., 1., 1., 1., 3., 3., 3., 1., 2., 3., 3., 1., 2.,\n",
       "        3., 1., 0., 2., 1., 3., 2., 3., 1., 1., 3., 1., 1., 2., 2., 1., 1.,\n",
       "        1., 1., 1., 2., 1., 1., 1., 1., 0., 1., 3., 3., 2., 1., 1., 1., 0.,\n",
       "        1., 1., 2., 1., 1., 0., 1., 2., 1., 0., 3., 1., 1., 2., 3., 3., 3.,\n",
       "        0., 2., 3., 1., 1., 0., 3., 3., 2., 3., 1., 1., 1., 0., 3., 1., 1.,\n",
       "        3., 3., 3., 1., 1., 3., 1., 2., 2., 2., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 3., 2., 1., 3., 3., 1., 1., 0., 3., 3., 0., 3., 2., 1., 3.,\n",
       "        1., 3., 1., 3., 0., 1., 1., 1., 3., 0., 2., 0., 0., 1., 1., 1., 2.,\n",
       "        0., 3., 1., 1., 1., 3., 3., 3., 3., 3., 1., 3., 3., 0., 3., 1., 3.,\n",
       "        1., 2., 1., 1., 1., 1., 1., 3., 3., 3., 1., 1., 0., 3., 1., 3., 1.,\n",
       "        0., 2., 0., 3., 1., 1., 2., 0., 1., 2., 0., 1., 1., 2., 0., 2., 0.,\n",
       "        1., 0., 3., 1., 3., 1., 3., 2., 3., 1., 0., 0., 3., 3., 1., 1., 0.,\n",
       "        3., 1., 3., 3., 1., 3., 0., 1., 3., 0., 1., 3., 1., 0., 1., 0., 1.,\n",
       "        0., 3., 2., 1., 1., 0., 2., 1.]),\n",
       " array([[0.38233751, 0.16688807, 0.28526288, 0.16551149],\n",
       "        [0.18866435, 0.17190786, 0.19623485, 0.4431929 ],\n",
       "        [0.18196638, 0.1791213 , 0.46251863, 0.17639373],\n",
       "        ...,\n",
       "        [0.47491366, 0.17479961, 0.17490625, 0.17538045],\n",
       "        [0.17720373, 0.18078457, 0.46685243, 0.17515932],\n",
       "        [0.1738988 , 0.40506423, 0.24279481, 0.17824216]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, test_loader, 4, 'CRC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
